{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0sw7FiRkpzg1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pkz-dVxTqDCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create imblanced data sets for 2 classes\n",
        "features_2, output_2 = make_classification(n_samples = 3000,\n",
        "                                       n_features = 33,\n",
        "                                       n_informative = 10,\n",
        "                                       n_redundant = 3,\n",
        "                                       n_classes = 2,\n",
        "                                       weights = [.1, .9],\n",
        "                                       random_state=42\n",
        "                                      )\n",
        "\n",
        "\n",
        "#create imblanced data sets for 3 classes\n",
        "features_3, output_3 = make_classification(n_samples = 3000,\n",
        "                                       n_features = 33,\n",
        "                                       n_informative = 10,\n",
        "                                       n_redundant = 3,\n",
        "                                       n_classes = 3,\n",
        "                                       weights = [.05, .05, .9],\n",
        "                                       random_state=42\n",
        "                                      )\n",
        "\n",
        "#create imblanced data sets for 6 classes\n",
        "features_6, output_6 = make_classification(n_samples = 3000,\n",
        "                                       n_features = 33,\n",
        "                                       n_informative = 10,\n",
        "                                       n_redundant = 3,\n",
        "                                       n_classes = 6,\n",
        "                                       weights = [.01, .01, .01, .02, .05, .9 ],\n",
        "                                       random_state=42\n",
        "                                      )"
      ],
      "metadata": {
        "id": "puxq7dxtqDOV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########TRAINING, TEST AND VALIDATION DATA FOR 2 CLASS TASK############\n",
        "\n",
        "#set the 20% of the data as the test set. do not forget to fix the random_state. otherwise you will evalaute different data sets for each run.\n",
        "x_trainc20, x_testc2, y_trainc20, y_testc2 = train_test_split(features_2, output_2, test_size=0.2, random_state = 42)\n",
        "\n",
        "#set the 20% of the training data as the validation set. do not forget to fix the random_state. otherwise you will evalaute different data sets for each run.\n",
        "x_trainc2, x_validc2, y_trainc2, y_validc2 = train_test_split(x_trainc20, y_trainc20, test_size=0.2, random_state = 42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########TRAINING, TEST AND VALIDATION DATA FOR 3 CLASS TASK############\n",
        "\n",
        "#set the 20% of the data as the test set. do not forget to fix the random_state. otherwise you will evalaute different data sets for each run.\n",
        "x_trainc30, x_testc3, y_trainc30, y_testc3 = train_test_split(features_3, output_3, test_size=0.2, random_state = 42)\n",
        "\n",
        "#set the 20% of the training data as the validation set. do not forget to fix the random_state. otherwise you will evalaute different data sets for each run.\n",
        "x_trainc3, x_validc3, y_trainc3, y_validc3 = train_test_split(x_trainc30, y_trainc30, test_size=0.2, random_state = 42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########TRAINING, TEST AND VALIDATION DATA FOR 6 CLASS TASK############\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#set the 20% of the data as the test set. do not forget to fix the random_state. otherwise you will evalaute different data sets for each run.\n",
        "x_trainc60, x_testc6, y_trainc60, y_testc6 = train_test_split(features_6, output_6, test_size=0.2, random_state = 5)\n",
        "\n",
        "#set the 20% of the training data as the validation set. do not forget to fix the random_state. otherwise you will evalaute different data sets for each run.\n",
        "x_trainc6, x_validc6, y_trainc6, y_validc6 = train_test_split(x_trainc60, y_trainc60, test_size=0.2, random_state = 5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wjt4NlRTqDkS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "4znVkyb_qJKO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lpy9LvCOohdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UU0n0wwOohRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define classifier function\n",
        "def classifier( train_data, train_target, test_data, test_target,estim,parameters,number_cv,verbose=1 ,score ='roc_auc_ovo'):\n",
        "\n",
        "  \"\"\"\n",
        "  This function aims to initially perform parameter search on the training data using grid search.\n",
        "   Afterward, it evaluates the classifier's results on the test data in terms of ROC AUC score and mean square error.\n",
        "\n",
        "  \"\"\"\n",
        "  #define grid search function\n",
        "  grid_search = GridSearchCV(estimator = estim, param_grid = parameters,cv = number_cv, n_jobs=-1, verbose=1, scoring=score)\n",
        "  #fit the grid search function to your training data.\n",
        "  grid_search.fit(train_data, train_target)\n",
        "  #it gives you the classifier which gives the best combination\n",
        "  last_estim = grid_search.best_estimator_\n",
        "  #I need probability estimates; then, I need to convert the target array, which I can calculate probability estimates after predictions\n",
        "  enc = OneHotEncoder()\n",
        "  #before fit the data reshape it\n",
        "  enc.fit(test_target.reshape(-1, 1))\n",
        "  test_target = enc.transform(test_target.reshape(-1, 1)).toarray()\n",
        "\n",
        "  roc_auc= roc_auc_score(test_target, last_estim.predict_proba(test_data), multi_class='ovr')\n",
        "  mse = mean_squared_error(test_target, last_estim.predict_proba(test_data))\n",
        "  return roc_auc, mse\n"
      ],
      "metadata": {
        "id": "ly8gEyAWKnLJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada_version1 = AdaBoostClassifier(random_state=42)\n",
        "ada_version2 = AdaBoostClassifier(random_state=42)\n",
        "ada_version3 = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "\n",
        "paramsada = {\n",
        "\n",
        "    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
        "    'n_estimators': [10,25,30,50,100,200]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "roc_adav1, mse_adav1 =  classifier(x_trainc2, y_trainc2, x_testc2, y_testc2, ada_version1, paramsada, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_adav1, mse_adav1)\n",
        "\n",
        "roc_adav2, mse_adav2 =  classifier(x_trainc3, y_trainc3, x_testc3, y_testc3, ada_version2, paramsada, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_adav2, mse_adav2)\n",
        "\n",
        "roc_adav3, mse_adav3 =  classifier(x_trainc6, y_trainc6, x_testc6, y_testc6, ada_version3, paramsada, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_adav3, mse_adav3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1PUaeDUanjO",
        "outputId": "d36fed06-bfd3-42fc-e743-1e941241378c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
            "0.8920685608231665 0.2040553534747273\n",
            "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
            "0.7821617845668648 0.12939986120242106\n",
            "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
            "0.6007588876686442 0.05340734102470318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_version1 = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "random_version2 = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "random_version3 = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "params = {\n",
        "    'max_depth': [2,3,5,10,20],\n",
        "    'min_samples_leaf': [5,10,20,50,100,200],\n",
        "    'n_estimators': [10,25,30,50,100,200]\n",
        "}\n",
        "\n",
        "roc_random1, mse_random1 =  classifier(x_trainc2, y_trainc2, x_testc2, y_testc2, random_version1, params, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_random1, mse_random1)\n",
        "\n",
        "roc_random2, mse_random2 =  classifier(x_trainc3, y_trainc3, x_testc3, y_testc3, random_version2, params, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_random2, mse_random2)\n",
        "\n",
        "roc_random3, mse_random3 =  classifier(x_trainc6, y_trainc6, x_testc6, y_testc6, random_version3, params, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_random3, mse_random3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2yKvr9ecj_R",
        "outputId": "71cb09b0-5bd4-4e65-ff75-6f497c31ef0c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n",
            "0.9235514069707143 0.06408894821182361\n",
            "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n",
            "0.8699478361290115 0.045924708461993535\n",
            "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n",
            "0.749256409081641 0.02834870455272587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.calibration import calibration_curve\n",
        "from matplotlib import pyplot\n",
        "\n",
        "#define classifier function\n",
        "def classifier_calibrated( train_data, train_target,val_data, val_target, test_data, test_target,estim,parameters,number_cv,verbose=1 ,score ='roc_auc_ovo'):\n",
        "\n",
        "  \"\"\"\n",
        "  This function aims to initially perform parameter search on the training data using grid search.\n",
        "   Afterward, it evaluates the classifier's results on the test data in terms of ROC AUC score and mean square error.\n",
        "\n",
        "  \"\"\"\n",
        "  #define grid search function\n",
        "  grid_search = GridSearchCV(estimator = estim, param_grid = parameters,cv = number_cv, n_jobs=-1, verbose=1, scoring=score)\n",
        "  #fit the grid search function to your training data.\n",
        "  grid_search.fit(train_data, train_target)\n",
        "  #it gives you the classifier which gives the best combination\n",
        "  last_estim = grid_search.best_estimator_\n",
        "  #I need probability estimates; then, I need to convert the target array, which I can calculate probability estimates after predictions\n",
        "  enc = OneHotEncoder()\n",
        "  enc2 = OneHotEncoder()\n",
        "  #before fit the data reshape it\n",
        "  enc.fit(test_target.reshape(-1, 1))\n",
        "  enc2.fit(val_target.reshape(-1, 1))\n",
        "  test_target = enc.transform(test_target.reshape(-1, 1)).toarray()\n",
        "  #val_target = enc2.transform(val_target.reshape(-1, 1)).toarray()\n",
        "  # calibrate model on validation data\n",
        "  calibrator = CalibratedClassifierCV(last_estim,method='sigmoid')\n",
        "  calibrator.fit(val_data, val_target)\n",
        "  # evaluate the model\n",
        "  last_estim_cal = calibrator.predict_proba(test_data)\n",
        "\n",
        "  roc_auc= roc_auc_score(test_target, last_estim_cal , multi_class='ovr')\n",
        "  mse = mean_squared_error(test_target, last_estim_cal )\n",
        "  return roc_auc, mse\n"
      ],
      "metadata": {
        "id": "wxcqk_v8c9mC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_adav1_cal, mse_adav1_cal =  classifier_calibrated(x_trainc2, y_trainc2, x_validc2, y_validc2,  x_testc2, y_testc2, ada_version1, paramsada, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_adav1_cal, mse_adav1_cal)\n",
        "\n",
        "roc_adav2_cal, mse_adav2_cal =  classifier_calibrated(x_trainc3, y_trainc3, x_validc3, y_validc3,  x_testc3, y_testc3, ada_version2, paramsada, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_adav2_cal, mse_adav2_cal)\n",
        "\n",
        "\n",
        "roc_adav3_cal, mse_adav3_cal =  classifier_calibrated(x_trainc6, y_trainc6, x_validc6, y_validc6,  x_testc6, y_testc6, ada_version3, paramsada, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_adav3_cal, mse_adav3_cal)\n"
      ],
      "metadata": {
        "id": "sMS3Hm12Bw-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee979b7f-3cfc-4cca-ee0a-4d63db749ece"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
            "0.8582111957204072 0.08380148069486756\n",
            "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
            "0.6321991792336137 0.06262205369899433\n",
            "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
            "0.6248164548642703 0.03192652826553554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ipGhgkNhEGTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_randomv1_cal, mse_randomv1_cal =  classifier_calibrated(x_trainc2, y_trainc2, x_validc2, y_validc2,  x_testc2, y_testc2, random_version1, params, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_adav1_cal, mse_adav1_cal)\n",
        "\n",
        "roc_randomv2_cal, mse_randomv2_cal =  classifier_calibrated(x_trainc3, y_trainc3, x_validc3, y_validc3,  x_testc3, y_testc3, random_version2, params, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_adav2_cal, mse_adav2_cal)\n",
        "\n",
        "\n",
        "roc_randomv3_cal, mse_randomv3_cal =  classifier_calibrated(x_trainc6, y_trainc6, x_validc6, y_validc6,  x_testc6, y_testc6, random_version3, params, 4,1 ,'roc_auc_ovo')\n",
        "print(roc_adav3_cal, mse_adav3_cal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w-ljssYEGGf",
        "outputId": "ecb82bdc-cd8a-499a-bc70-e86b58321d08"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n",
            "0.8582111957204072 0.08380148069486756\n",
            "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n",
            "0.6321991792336137 0.06262205369899433\n",
            "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n",
            "0.6248164548642703 0.03192652826553554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_randomv1_cal, mse_randomv1_cal)\n",
        "\n",
        "print(roc_randomv2_cal, mse_randomv2_cal)\n",
        "\n",
        "print(roc_randomv3_cal, mse_randomv3_cal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FTJuvFa4asr",
        "outputId": "825ff2fd-e742-4b42-bb67-f8e8f15bde40"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8208739321488032 0.07977300673700467\n",
            "0.7719904241723518 0.051478847065914095\n",
            "0.6602049347617239 0.029941022330675884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'After calibration MSE score for the Adaboost algorithm was improved by {(mse_adav1- mse_adav1_cal)/mse_adav1:.2%} for the two class classification task.')\n",
        "\n",
        "print(f'After calibration MSE score for the Adaboost algorithm was improved by {(mse_adav2 - mse_adav2_cal)/mse_adav2:.2%} for the three class classification task.')\n",
        "\n",
        "print(f'After calibration MSE score for the Adaboost algorithm was improved by {(mse_adav3 - mse_adav3_cal)/mse_adav3:.2%} for the six class classification task.')"
      ],
      "metadata": {
        "id": "YLvMN8R6OBOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d200063f-082b-4809-94e2-2b2498965e95"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After calibration MSE score for the Adaboost algorithm was improved by 58.93% for the two class classification task.\n",
            "After calibration MSE score for the Adaboost algorithm was improved by 51.61% for the three class classification task.\n",
            "After calibration MSE score for the Adaboost algorithm was improved by 40.22% for the six class classification task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'After calibration MSE score for the Random Forests algorithm was degraded by {(mse_random1 - mse_randomv1_cal)/mse_random1:.2%} for the two class classification task.')\n",
        "\n",
        "print(f'After calibration MSE score for the Random Forests algorithm was degraded by {(mse_random2 - mse_randomv2_cal)/mse_random2:.2%} for the three class classification task.')\n",
        "\n",
        "print(f'After calibration MSE score for the Random Forests algorithm was degraded by {(mse_random3 - mse_randomv3_cal)/mse_random3:.2%} for the six class classification task.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDpSdIleNVK1",
        "outputId": "7b930b48-ed77-4ad8-d6c7-8a7396563cb4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After calibration MSE score for the Random Forests algorithm was degraded by -24.47% for the two class classification task.\n",
            "After calibration MSE score for the Random Forests algorithm was degraded by -12.09% for the three class classification task.\n",
            "After calibration MSE score for the Random Forests algorithm was degraded by -5.62% for the six class classification task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observed that probability calibration **improved** the performance of the *Adaboost* classifier in terms of mean square error. However, for the *Random Forest* algorithm, **performance degraded** after calibration. Moreover, as the **number of classes** increased, **the effect of calibration decreased** for both Adaboost and Random Forest algorithms."
      ],
      "metadata": {
        "id": "tCIXpMxVUofR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5TJMfCYIOY5M"
      }
    }
  ]
}